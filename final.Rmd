---
title: "final project"
author: "Aiying Huang"
date: "2023-12-01"
output: 
  pdf_document:
    latex_engine: xelatex
---


# 描述性统计

## 变量分布

```{r}
#| echo: false
#| message: false
# Load necessary libraries
library(dplyr)
library(tidyr)
library(ggplot2)
library(GGally)
library(gridExtra)

# Read the data
data <- read.csv("./Project_1_data.csv")
data[data == ""] <- NA
# 1. Descriptive statistics table for all variables
skimr::skim(data)

# 2. Explore distribution of results and consider potential transformations
# Histograms for continuous variables
hist_math <- ggplot(data, aes(x = MathScore)) + geom_histogram(bins = 30) + ggtitle("Histogram of Math Scores")
hist_reading <- ggplot(data, aes(x = ReadingScore)) + geom_histogram(bins = 30) + ggtitle("Histogram of Reading Scores")
hist_writing <- ggplot(data, aes(x = WritingScore)) + geom_histogram(bins = 30) + ggtitle("Histogram of Writing Scores")

# Boxplots for continuous variables to check for outliers
box_math <- ggplot(data, aes(y = MathScore)) + geom_boxplot() + ggtitle("Boxplot of Math Scores")
box_reading <- ggplot(data, aes(y = ReadingScore)) + geom_boxplot() + ggtitle("Boxplot of Reading Scores")
box_writing <- ggplot(data, aes(y = WritingScore)) + geom_boxplot() + ggtitle("Boxplot of Writing Scores")

# Grid of plots
grid.arrange(hist_math, hist_reading, hist_writing, box_math, box_reading, box_writing, ncol = 3)

# 3. Check for potential outliers or influential points
# Scatterplot matrix for continuous variables
ggpairs(data, columns = c("MathScore", "ReadingScore", "WritingScore"))

```


## 缺失值

```{r}
#| echo: false
#| message: false
# Load necessary libraries
library(ggplot2)
library(reshape2)


# Creating a function to count NA and empty strings as missing values
count_missing <- function(x) sum(is.na(x) | x == "")
# Calculating the missing values
missing_values <- sapply(data, function(x) count_missing(x))

# Creating a dataframe for missing values
missing_data_frame <- data.frame(Variable = names(missing_values), MissingValues = missing_values)

# Convert empty strings to NA
data[data == ""] <- NA

# Melt the data for visualization
melted_data <- melt(data.frame(row = 1:nrow(data), data), id.vars = 'row')

# Creating the heatmap
ggplot(melted_data, aes(x = variable, y = row)) + 
  geom_tile(aes(fill = is.na(value))) + 
  scale_fill_manual(values = c('white', 'red'), guide = FALSE) + 
  theme_minimal() + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(x = 'Variables', y = 'Observation Rows', title = 'Missing Data Heatmap')
```
```{r}
#| echo: false
#| message: false
missing_data_frame
```




# 数据预处理

## 缺失值填补

```{r}
#| echo: false
#| message: false
# Imputing missing values
# For columns with fewer missing values, replace with mode
get_mode <- function(v) {
  uniqv <- unique(v)
  uniqv[which.max(tabulate(match(v, uniqv)))]
}

data$PracticeSport[is.na(data$PracticeSport)] <- get_mode(data$PracticeSport)
data$IsFirstChild[is.na(data$IsFirstChild)] <- get_mode(data$IsFirstChild)

# For columns with more missing values, you can choose to impute or drop
# Imputing with mode (as an example)
data$EthnicGroup[is.na(data$EthnicGroup)] <- get_mode(data$EthnicGroup)
data$ParentEduc[is.na(data$ParentEduc)] <- get_mode(data$ParentEduc)
data$TestPrep[is.na(data$TestPrep)] <- get_mode(data$TestPrep)
data$ParentMaritalStatus[is.na(data$ParentMaritalStatus)] <- get_mode(data$TestPrep)
data$WklyStudyHours[is.na(data$WklyStudyHours)]<- get_mode(data$WklyStudyHours)
data$NrSiblings[is.na(data$NrSiblings)] <- get_mode(data$NrSiblings)

# Alternatively, to drop rows with NA values in these columns-TransportMeans
data <- data %>% drop_na(TransportMeans)
```


```{r}
#| echo: false
#| message: false
# Creating a function to count NA and empty strings as missing values
count_missing <- function(x) sum(is.na(x) | x == "")
# Calculating the missing values
missing_values <- sapply(data, function(x) count_missing(x))

# Creating a dataframe for missing values
missing_data_frame <- data.frame(Variable = names(missing_values), MissingValues = missing_values)

```





# 检查变量之间的边际分布和成对关系-correlation/pairwise
## Examine the marginal distributions and pairwise relationships between variables

```{r, message=FALSE}
# Load necessary libraries
library(tidyverse)
library(ggplot2) 
library(GGally)

# draw the pariplot
ggpairs(data, columns=1:14, aes(alpha = 0.3))+ 
  theme_bw()
```
这边感觉没有别的办法了，最后都是这个14*14的图，感觉不行我们直接这样然后说没看到obvious nonlinearities

## Correlation between variables
```{r}
# Load necessary libraries
library(greybox)
library(tidyverse)
library(corrplot)

# Compute the Cramer's V correlation between variables
cramer_v_matrix <- assoc(data, method = "auto")

# Extract the matrix with Cramer's V values
cramer_v_values <- as.matrix(cramer_v_matrix$value)

# Print the correlation matrix results
knitr::kable(cramer_v_values, digits = 3)

# Create a heatmap
corrplot(cramer_v_values, type = "upper", order = "hclust", 
         tl.col = "black", tl.srt = 45)
```
（这个变量的解释）Cramér's V (for categorical variables) varies from 0 (corresponding to no association between the variables) to 1 (complete association) and can reach 1 only when each variable is completely determined by the other.

这边有很多no relation的（很正常），predicators没有哪两个是colinear的
这边auto的话，会自动选这几种correlation的compare方法： Strength of association is calculated for nominal vs nominal with a bias corrected Cramer's V, numeric vs numeric with Spearman (default) or Pearson correlation, and nominal vs numeric with ANOVA.


```{r}
#| echo: false
#| message: false
library(car)
set.seed(123) 
splitRatio <- 0.8

trainIndex <- sample(seq_len(nrow(data)), size = floor(splitRatio * nrow(data)))
trainData <- data[trainIndex, ]
testData <- data[-trainIndex, ]

# Splitting the train dataset into independent variables (X) and dependent variables (Y)
X_train <- trainData %>% select(-c(MathScore, ReadingScore, WritingScore))
Y_math_train <- trainData$MathScore
Y_reading_train <-trainData$ReadingScore
Y_writing_train <- trainData$WritingScore

```

即使两个变量之间存在统计关联，也不一定意味着它们会导致严重的多重共线性。例如，两个变量可能在某些类别上有统计关联，但它们的整体线性关系可能不强。所以都纳入模型
#####################################################################################################

# Model Selection

Despite the absence of discernible linear correlations among the variables, the inclusion of interaction terms is justified, guided by prior theoretical knowledge and practical considerations.

```{r}
# Checking for interaction effects (example for math score)
full_model_math_interaction <- lm(Y_math_train ~  (.)^2, data = X_train)
full_model_reading_interaction <- lm(Y_reading_train ~  (.)^2, data = X_train)
full_model_writing_interaction <- lm(Y_writing_train ~  (.)^2, data = X_train)

# backward modeling(compare)
AICmodel_math_interaction = 
  step(full_model_math_interaction, trace = 0, direction='backward')
BICmodel_math_interaction = 
  step(full_model_math_interaction, scale = log(nrow(X_train)), trace = 0, direction='backward')

# show parameter numbers
num_params_AICmodel <- length(coef(AICmodel_math_interaction))
num_params_BICmodel <- length(coef(BICmodel_math_interaction))

cat("AIC Model Parameters:", num_params_AICmodel, "\n")
cat("BIC Model Parameters:", num_params_BICmodel, "\n")

```

Consequently, a comprehensive model was formulated, encompassing all 11 independent variables along with their respective pairwise interaction terms. In the ensuing stages of the analysis, a focus will be maintained on selecting a parsimonious subset of variables, with an aim to mitigate the risk of overfitting.

```{r}
# try AIC and BIC
model_math_interaction = AICmodel_math_interaction
model_reading_interaction =
  step(full_model_reading_interaction, trace = 0, direction='backward')
model_writing_interaction =
  step(full_model_writing_interaction, trace = 0, direction='backward')

# results
# r.squared
glance_math = broom::glance(model_math_interaction) |>
  mutate(model = "Math") |>
  select(model, r.squared, adj.r.squared, p.value, AIC, BIC) 

glance_reading = broom::glance(model_reading_interaction) |>
  mutate(model = "Reading") |>
  select(model, r.squared, adj.r.squared, p.value, AIC, BIC) 

glance_writing = broom::glance(model_writing_interaction) |>
  mutate(model = "Writing") |>
  select(model, r.squared, adj.r.squared, p.value, AIC, BIC) 

bind_rows(glance_math, glance_reading, glance_writing) |>
  knitr::kable()
  
# coef
broom::tidy(model_math_interaction) |>
  knitr::kable(caption = "Math")
broom::tidy(model_reading_interaction) |>
  knitr::kable(caption = "Reading")
broom::tidy(model_writing_interaction) |>
  knitr::kable(caption = "Writing")
```

Initially, we performed a approach combining automated procedures and criterion-based with both the Akaike Information Criterion (AIC) and the Bayesian Information Criterion (BIC) for model selection. It was observed that the application of the AIC criterion resulted in a model with fewer variables. Thus, we utilized the AIC criterion for backward elimination.

```{r}
# try LASSO
library(glmnet)

X_math <- model.matrix(~ Gender + EthnicGroup + ParentEduc + 
                   LunchType + TestPrep + ParentMaritalStatus + 
                   PracticeSport + IsFirstChild + NrSiblings + 
                   TransportMeans + WklyStudyHours + 
                   Gender:LunchType + Gender:PracticeSport + 
                   EthnicGroup:ParentEduc + EthnicGroup:IsFirstChild + 
                   ParentEduc:TestPrep + ParentEduc:ParentMaritalStatus + 
                   ParentEduc:PracticeSport + ParentEduc:IsFirstChild + 
                   LunchType:PracticeSport + LunchType:TransportMeans + 
                   TestPrep:WklyStudyHours + ParentMaritalStatus:PracticeSport + ParentMaritalStatus:IsFirstChild + ParentMaritalStatus:TransportMeans + PracticeSport:WklyStudyHours + IsFirstChild:NrSiblings + IsFirstChild:TransportMeans + IsFirstChild:WklyStudyHours, 
                   data = X_train)
# cv
cv_model <- cv.glmnet(X_math, Y_math_train, alpha = 1)
best_lambda <- cv_model$lambda.min
lasso_model <- glmnet(X_math, Y_math_train, alpha = 1, lambda = best_lambda)

coef(lasso_model)

model_math_best = lm(Y_math_train ~  Gender + EthnicGroup + ParentEduc + LunchType + TestPrep + ParentMaritalStatus + PracticeSport + TransportMeans + WklyStudyHours + Gender:PracticeSport + EthnicGroup:ParentEduc + ParentEduc:ParentMaritalStatus + + ParentEduc:PracticeSport + LunchType:PracticeSport + ParentMaritalStatus:TransportMeans + PracticeSport:WklyStudyHours, data = X_train)
```

```{r}
# reading LASSO

X_reading <- model.matrix(~ Gender + EthnicGroup + ParentEduc + 
    LunchType + TestPrep + ParentMaritalStatus + PracticeSport + 
    IsFirstChild + NrSiblings + TransportMeans + WklyStudyHours + 
    Gender:IsFirstChild + LunchType:PracticeSport + LunchType:IsFirstChild + 
    TestPrep:NrSiblings + TestPrep:TransportMeans + ParentMaritalStatus:PracticeSport + ParentMaritalStatus:IsFirstChild + PracticeSport:WklyStudyHours + NrSiblings:WklyStudyHours, data = X_train)

# cv
cv_model <- cv.glmnet(X_reading, Y_reading_train, alpha = 1)
best_lambda <- cv_model$lambda.min
lasso_model <- glmnet(X_reading, Y_reading_train, alpha = 1, lambda = best_lambda)
coef(lasso_model)

model_reading_best = lm(Y_reading_train ~ Gender + EthnicGroup + ParentEduc + 
    LunchType + TestPrep + ParentMaritalStatus + PracticeSport + 
    IsFirstChild + NrSiblings + TransportMeans + WklyStudyHours + LunchType:PracticeSport + ParentMaritalStatus:PracticeSport + ParentMaritalStatus:IsFirstChild + PracticeSport:WklyStudyHours + NrSiblings:WklyStudyHours, data = X_train)
```

```{r}
X_writing <- model.matrix(~ Gender + EthnicGroup + ParentEduc + 
    LunchType + TestPrep + ParentMaritalStatus + PracticeSport + 
    IsFirstChild + NrSiblings + TransportMeans + WklyStudyHours + 
    ParentEduc:IsFirstChild + LunchType:PracticeSport + LunchType:IsFirstChild + 
    TestPrep:NrSiblings + ParentMaritalStatus:PracticeSport + 
    ParentMaritalStatus:IsFirstChild + PracticeSport:WklyStudyHours + 
    IsFirstChild:WklyStudyHours, data = X_train)

# cv
cv_model <- cv.glmnet(X_writing, Y_writing_train, alpha = 1)
best_lambda <- cv_model$lambda.min
lasso_model <- glmnet(X_writing, Y_writing_train, alpha = 1, lambda = best_lambda)
coef(lasso_model)

model_writing_best = lm(Y_writing_train ~ Gender + EthnicGroup + ParentEduc + 
    LunchType + TestPrep + ParentMaritalStatus + PracticeSport + 
    IsFirstChild + NrSiblings + TransportMeans + WklyStudyHours + 
    ParentEduc:IsFirstChild + LunchType:PracticeSport + 
    TestPrep:NrSiblings + ParentMaritalStatus:PracticeSport + 
    ParentMaritalStatus:IsFirstChild + PracticeSport:WklyStudyHours + 
    IsFirstChild:WklyStudyHours, data = X_train) 
```

However, the initial process leaving a considerable number of variables, we applied the LASSO (Least Absolute Shrinkage and Selection Operator) method for penalization. Utilizing cross-validation (cv), we identified the optimal lambda value. Subsequently, all interaction terms with shrinkage coefficients (s0) below 0.5 were eliminated. This refined approach resulted in the derivation of three models that were not only more efficient but also nested.

```{r, message=FALSE, warning=FALSE}
par(mfrow=c(2,2))
plot(model_math_best) 
mtext("Math Model Diagnostic", outer = TRUE, cex = 1, line = -1)

plot(model_reading_best)
mtext("Reading Model Diagnostic", outer = TRUE, cex = 1, line = -1)

plot(model_writing_best)
mtext("Writing Model Diagnostic", outer = TRUE, cex = 1, line = -1)
```

In the diagnostic analysis of our linear regression model, the Residuals versus Fitted values plot exhibited a stochastic distribution of residuals, devoid of any systematic patterns, thereby conforming to the assumptions of homoscedasticity and linearity. The Quantile-Quantile (QQ) plot demonstrated a close alignment of residuals with the theoretical normal distribution, as evidenced by the linear arrangement of data points. Furthermore, the Scale-Location plot revealed a uniform dispersion of residuals around a central horizontal axis, indicative of consistent variance across the spectrum of fitted values. Finally, the examination of the Residuals versus Leverage plot revealed an absence of high-leverage observations, thus suggesting that the model is not unduly influenced by outlier data points.

## Influential observations

```{r}
par(mfrow=c(1,3))
plot(model_math_best, which = 4)
plot(model_reading_best, which = 4)
plot(model_writing_best, which = 4)
```


From the analysis of the plots, we identified a few points that appeared to be potential outliers or high-influence observations. However, upon examination, the Cook's distance values for these points were not significantly large. Additionally, when these points were excluded and the model was re-estimated, there was no substantial change in the model's performance. Upon further investigation of these specific data points, no anomalies were detected. Consequently, the final model was retained with these data points included.

## multicolinearity-没有强烈的多重共线性问题

```{r, warning=FALSE, message=FALSE}
vif_values_math <- vif(model_math_best , type = 'predictor')
print(vif_values_math)
vif_values_writing <- vif(model_writing_best, type = 'predictor')
print(vif_values_writing)
vif_values_reading <- vif(model_reading_best, type = 'predictor')
print(vif_values_reading)
```

## model validation

# cross validation
```{r, warning=FALSE}
#| echo: false
#| message: false
library(caret)
control <- trainControl(method = "cv", number = 10)
set.seed(123)
math_model_data <- cbind(X_train, Y_math_train)
math_model_cv <- train( Y_math_train ~ Gender + EthnicGroup + ParentEduc + LunchType + TestPrep + ParentMaritalStatus + PracticeSport + TransportMeans + WklyStudyHours + Gender:PracticeSport + EthnicGroup:ParentEduc + ParentEduc:ParentMaritalStatus + + ParentEduc:PracticeSport + LunchType:PracticeSport + ParentMaritalStatus:TransportMeans + PracticeSport:WklyStudyHours, 
    data = math_model_data, method = "lm", trControl = control)

set.seed(124)
reading_model_data <- cbind(X_train, Y_reading_train)
reading_model_cv <- train(Y_reading_train ~ Gender + EthnicGroup + ParentEduc + 
    LunchType + TestPrep + ParentMaritalStatus + PracticeSport + 
    IsFirstChild + NrSiblings + TransportMeans + WklyStudyHours + LunchType:PracticeSport + ParentMaritalStatus:PracticeSport + ParentMaritalStatus:IsFirstChild + PracticeSport:WklyStudyHours + NrSiblings:WklyStudyHours, data = reading_model_data,
    method = "lm", trControl = control)

set.seed(125)
writing_model_data <- cbind(X_train, Y_writing_train)
writing_model_cv <- train(Y_writing_train ~ Gender + EthnicGroup + ParentEduc + 
    LunchType + TestPrep + ParentMaritalStatus + PracticeSport + 
    IsFirstChild + NrSiblings + TransportMeans + WklyStudyHours + 
    ParentEduc:IsFirstChild + LunchType:PracticeSport + 
    TestPrep:NrSiblings + ParentMaritalStatus:PracticeSport + 
    ParentMaritalStatus:IsFirstChild + PracticeSport:WklyStudyHours + 
    IsFirstChild:WklyStudyHours, data = writing_model_data, 
    method = "lm", trControl = control)


print(math_model_cv)
print(reading_model_cv)
print(writing_model_cv)


```

```{r}
library(readr)
library(dplyr)
library(ggplot2)
library(caret)
library(purrr)
library(tidyverse)
library(plotly)
library(modelr)
library(tidyr)
library(randomForest)
library(boot)
library(patchwork)

set.seed(123)
# generate a cv dataframe 
cv_df_math =
  crossv_mc(math_model_data, 10) %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))

# fit the model to the generated CV dataframe
cv_df_math =
  cv_df_math |> 
  mutate(
    model  = map(train, ~lm( Y_math_train ~ Gender + EthnicGroup + ParentEduc + LunchType + TestPrep + ParentMaritalStatus + PracticeSport + TransportMeans + WklyStudyHours + Gender:PracticeSport + EthnicGroup:ParentEduc + ParentEduc:ParentMaritalStatus + + ParentEduc:PracticeSport + LunchType:PracticeSport + ParentMaritalStatus:TransportMeans + PracticeSport:WklyStudyHours, 
    data = math_model_data)),
    rmse = map2_dbl(model, test, ~rmse(model = .x, data = .y)))

# plot the prediction error
plot_math <- cv_df_math |>
  select(rmse) |> 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse") %>% 
  ggplot(aes(x = model, y = rmse)) + 
  geom_violin(fill = "blue", alpha = 0.5) +
  labs(
    x = "Math",
    y = "Prediction Errors"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5),
    axis.text = element_text(color = "grey20"),
    axis.title = element_text(color = "grey20")
  )


set.seed(123)
# generate a cv dataframe 
cv_df_reading =
  crossv_mc(reading_model_data, 10) %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))

# fit the model to the generated CV dataframe
cv_df_reading =
  cv_df_reading |> 
  mutate(
    model  = map(train, ~lm(Y_reading_train ~ Gender + EthnicGroup + ParentEduc + 
    LunchType + TestPrep + ParentMaritalStatus + PracticeSport + 
    IsFirstChild + NrSiblings + TransportMeans + WklyStudyHours + LunchType:PracticeSport + ParentMaritalStatus:PracticeSport + ParentMaritalStatus:IsFirstChild + PracticeSport:WklyStudyHours + NrSiblings:WklyStudyHours, data = reading_model_data)),
    rmse = map2_dbl(model, test, ~rmse(model = .x, data = .y)))

# plot the prediction error
plot_reading <- cv_df_reading |>
  select(rmse) |> 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse") %>% 
  ggplot(aes(x = model, y = rmse)) + 
  geom_violin(fill = "pink", alpha = 0.5) +
  labs(
    x = "Reading",
    y = "Prediction Errors"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5),
    axis.text = element_text(color = "grey20"),
    axis.title = element_text(color = "grey20")
  )

set.seed(123)
# generate a cv dataframe 
cv_df_writing =
  crossv_mc(writing_model_data, 10) %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))

# fit the model to the generated CV dataframe
cv_df_writing =
  cv_df_writing |> 
  mutate(
    model  = map(train, ~lm(Y_writing_train ~ Gender + EthnicGroup + ParentEduc + 
    LunchType + TestPrep + ParentMaritalStatus + PracticeSport + 
    IsFirstChild + NrSiblings + TransportMeans + WklyStudyHours + 
    ParentEduc:IsFirstChild + LunchType:PracticeSport + 
    TestPrep:NrSiblings + ParentMaritalStatus:PracticeSport + 
    ParentMaritalStatus:IsFirstChild + PracticeSport:WklyStudyHours + 
    IsFirstChild:WklyStudyHours, data = writing_model_data)),
    rmse = map2_dbl(model, test, ~rmse(model = .x, data = .y)))

# plot the prediction error
plot_writing <-cv_df_writing |>
  select(rmse) |> 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse") %>% 
  ggplot(aes(x = model, y = rmse)) + 
  geom_violin(fill = "yellow", alpha = 0.5) +
  labs(
    x = "Writing",
    y = "Prediction Errors"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5),
    axis.text = element_text(color = "grey20"),
    axis.title = element_text(color = "grey20")
  )

plot_math + plot_reading + 
  plot_writing+plot_annotation(title="Prediction Errors For Models Under CV")
```



# prediction

```{r}
# Splitting the train dataset into independent variables (X) and dependent variables (Y)
X_test<- testData %>% select(-c(MathScore, ReadingScore, WritingScore))
Y_math_test <- testData$MathScore
Y_reading_test <-testData$ReadingScore
Y_writing_test <- testData$WritingScore
```


```{r, warning=FALSE}
math_predictions <- predict(model_math_best, newdata = X_test)
reading_predictions <- predict(model_reading_best, newdata = X_test)
writing_predictions <- predict(model_writing_best, newdata = X_test)
```


```{r}
math_mspe <- mean((Y_math_test - math_predictions)^2)
reading_mspe <- mean((Y_reading_test - reading_predictions)^2)
writing_mspe <- mean((Y_writing_test - writing_predictions)^2)
mspe_values <- data.frame(
  Subject = c("Math", "Reading", "Writing"),
  MSPE = c(math_mspe, reading_mspe, writing_mspe)
)
library(knitr)

kable(mspe_values, col.names = c("Subject", "MSPE"), caption = "MSPE Values for Different Subjects")
```









